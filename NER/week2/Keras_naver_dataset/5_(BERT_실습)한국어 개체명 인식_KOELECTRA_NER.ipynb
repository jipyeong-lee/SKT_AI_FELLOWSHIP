{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hctUswBCe6OI"
   },
   "source": [
    "# 한국어 개체명 인식 개요\n",
    "이번 강의에서는 버트를 활용해서 한국어 개체명 인식을 다뤄보고자 합니다. \n",
    "![Imgur](https://i.imgur.com/PDdTLjy.png) \n",
    "데이터는 https://github.com/naver/nlp-challenge/ 에서 받아왔습니다.\n",
    "\n",
    "개체명 추출 리더보드에서 제공되는 코퍼스는 문장에 나타난 개체명을 14개 분류 카테고리로 주석 작업이 되어있습니다.\n",
    "\n",
    "![Imgur](https://i.imgur.com/it4uTE3.png)\n",
    "\n",
    "문장을 입력하면 다음과 같은 형식으로 개체명이 분류됩니다.  \n",
    "\n",
    "![Imgur](https://i.imgur.com/RpuZf6R.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9NQjPIe3vE2"
   },
   "source": [
    "# 목차\n",
    "이번 실습은 <b>1) 네이버 개체명 인식 데이터 불러오기 및 전처리 2) BERT 인풋 만들기 3) 버트를 활용한 개체명 인식 모델 만들기 4) 훈련 및 성능 검증 5) 실제 데이터로 실습하기</b>로 구성되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMBwJT0r38tj"
   },
   "source": [
    "# BERT를 활용하여 한국어 개체명 인식기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Amc52mb94Jzq"
   },
   "source": [
    "## 개체명 인식 데이터 불러오기 및 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3rnyfkihRVq"
   },
   "source": [
    "개체명 인식을 위한 데이터를 다운 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1656133231444,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "2Xv5IzTBeecA",
    "outputId": "27734a35-f17f-4394-dffd-12e08c3b0d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-25 05:28:59--  https://github.com/naver/nlp-challenge/raw/master/missions/ner/data/train/train_data\n",
      "Resolving github.com (github.com)... 52.78.231.108\n",
      "Connecting to github.com (github.com)|52.78.231.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/naver/nlp-challenge/master/missions/ner/data/train/train_data [following]\n",
      "--2022-06-25 05:28:59--  https://raw.githubusercontent.com/naver/nlp-challenge/master/missions/ner/data/train/train_data\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16945023 (16M) [text/plain]\n",
      "Saving to: ‘train_data’\n",
      "\n",
      "train_data          100%[===================>]  16.16M  42.3MB/s    in 0.4s    \n",
      "\n",
      "2022-06-25 05:29:02 (42.3 MB/s) - ‘train_data’ saved [16945023/16945023]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/naver/nlp-challenge/raw/master/missions/ner/data/train/train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MeOwf3FhdgE"
   },
   "source": [
    "분석에 필요한 모듈들을 임포트 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12625,
     "status": "ok",
     "timestamp": 1656133391502,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "d0dhGSE3ehh-",
    "outputId": "b9df2296-8846-4dac-919e-63af1cda9753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/local/lib/python3.8/dist-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.16.2)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2020.2.20)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.5.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.55.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.25.10)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m/usr/local/lib/python3.8/dist-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/local/lib/python3.8/dist-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (0.0.43)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sacremoses) (4.55.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses) (0.14.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses) (1.15.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacremoses) (2020.2.20)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m/usr/local/lib/python3.8/dist-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/usr/local/lib/python3.8/dist-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.8/dist-packages (0.1.94)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pandas/compat/_optional.py:161: UserWarning: Pandas requires version '2.7.1' or newer of 'numexpr' (version '2.7.0' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sacremoses\n",
    "!pip install sentencepiece\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SBHyIvJhieB"
   },
   "source": [
    "train 데이터를 불러 오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1656133402718,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "45hQv0Bienkt",
    "outputId": "352f46b7-d8c8-4996-a83d-b9a5c8a11628"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>비토리오</td>\n",
       "      <td>PER_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>양일</td>\n",
       "      <td>DAT_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>만에</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>영사관</td>\n",
       "      <td>ORG_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>감호</td>\n",
       "      <td>CVL_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769060</th>\n",
       "      <td>2</td>\n",
       "      <td>어째</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769061</th>\n",
       "      <td>3</td>\n",
       "      <td>뭔가</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769062</th>\n",
       "      <td>4</td>\n",
       "      <td>수상쩍은</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769063</th>\n",
       "      <td>5</td>\n",
       "      <td>좌담</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769064</th>\n",
       "      <td>6</td>\n",
       "      <td>．</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>769065 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   src    tar\n",
       "0           1  비토리오  PER_B\n",
       "1           2    양일  DAT_B\n",
       "2           3    만에      -\n",
       "3           4   영사관  ORG_B\n",
       "4           5    감호  CVL_B\n",
       "...       ...   ...    ...\n",
       "769060      2    어째      -\n",
       "769061      3    뭔가      -\n",
       "769062      4  수상쩍은      -\n",
       "769063      5    좌담      -\n",
       "769064      6     ．      -\n",
       "\n",
       "[769065 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train_data\", names=['src', 'tar'], sep=\"\\t\")\n",
    "train = train.reset_index()\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eC2QfGRbhmJJ"
   },
   "source": [
    "train 데이터에 마침표가 이상한 것들이 많아서 확실하게 .으로 수정해 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ms0gXmslimQc"
   },
   "outputs": [],
   "source": [
    "train['src'] = train['src'].str.replace(\"．\", \".\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656133411793,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "X2zgWiWAhiXY",
    "outputId": "3f58fcba-2066-46b3-ff07-0378bd200b76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>10</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>24</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>19</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769013</th>\n",
       "      <td>11</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769036</th>\n",
       "      <td>23</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769053</th>\n",
       "      <td>17</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769058</th>\n",
       "      <td>5</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769064</th>\n",
       "      <td>6</td>\n",
       "      <td>.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57254 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index src tar\n",
       "15          6   .   -\n",
       "30         15   .   -\n",
       "40         10   .   -\n",
       "77         24   .   -\n",
       "96         19   .   -\n",
       "...       ...  ..  ..\n",
       "769013     11   .   -\n",
       "769036     23   .   -\n",
       "769053     17   .   -\n",
       "769058      5   .   -\n",
       "769064      6   .   -\n",
       "\n",
       "[57254 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[train['src']=='.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJHg2kIUht7L"
   },
   "source": [
    "데이터를 전처리 해주겠습니다.  \n",
    "한글, 영어, 소문자, 대문자, . 이외의 단어들을 모두 제거하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XnsxeMY9Z7vv"
   },
   "outputs": [],
   "source": [
    "train['src'] = train['src'].astype(str)\n",
    "train['tar'] = train['tar'].astype(str)\n",
    "\n",
    "train['src'] = train['src'].str.replace(r'[^ㄱ-ㅣ가-힣0-9a-zA-Z.]+', \"\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QekBoou4h1HK"
   },
   "source": [
    "데이터를 리스트 형식으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Gj8CBxAtGVpT"
   },
   "outputs": [],
   "source": [
    "data = [list(x) for x in train[['index', 'src', 'tar']].to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9Tup6qziOMA"
   },
   "source": [
    "데이터를 잘 보면 (인덱스, 단어, 개체) 로 이루어 진 것을 알 수 있습니다.  \n",
    "인덱스가 1,2,3,4,5.. 이렇게 이어지다가 다시 1,2,3,4, 로 바뀌는데 숫자가 바뀌기 전까지가 한 문장을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1656133422833,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "ETMBXgxPiH63",
    "outputId": "59108103-c848-42bc-f172-8e3d5cfc97b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, '비토리오', 'PER_B'], [2, '양일', 'DAT_B'], [3, '만에', '-'], [4, '영사관', 'ORG_B'], [5, '감호', 'CVL_B'], [6, '용퇴', '-'], [7, '항룡', '-'], [8, '압력설', '-'], [9, '의심만', '-'], [10, '가율', '-'], [1, '이', '-'], [2, '음경동맥의', '-'], [3, '직경이', '-'], [4, '8', 'NUM_B'], [5, '19mm입니다', 'NUM_B'], [6, '.', '-'], [1, '9세이브로', 'NUM_B'], [2, '구완', '-'], [3, '30위인', 'NUM_B'], [4, 'LG', 'ORG_B']]\n"
     ]
    }
   ],
   "source": [
    "print(data[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59Lv_fQKh7Lj"
   },
   "source": [
    "라벨들을 추출하고, 딕셔너리 형식으로 저장하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jQm5tzwSQVH_"
   },
   "outputs": [],
   "source": [
    "label = train['tar'].unique().tolist()\n",
    "label_dict = {word:i for i, word in enumerate(label)}\n",
    "label_dict.update({\"[PAD]\":len(label_dict)})\n",
    "index_to_ner = {i:j for j, i in label_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1656133426454,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "CCFeeGVoRos7",
    "outputId": "be0d3bbb-425e-410d-d1cf-6ad729c51245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PER_B': 0, 'DAT_B': 1, '-': 2, 'ORG_B': 3, 'CVL_B': 4, 'NUM_B': 5, 'LOC_B': 6, 'EVT_B': 7, 'TRM_B': 8, 'TRM_I': 9, 'EVT_I': 10, 'PER_I': 11, 'CVL_I': 12, 'NUM_I': 13, 'TIM_B': 14, 'TIM_I': 15, 'ORG_I': 16, 'DAT_I': 17, 'ANM_B': 18, 'MAT_B': 19, 'MAT_I': 20, 'AFW_B': 21, 'FLD_B': 22, 'LOC_I': 23, 'AFW_I': 24, 'PLT_B': 25, 'FLD_I': 26, 'ANM_I': 27, 'PLT_I': 28, '[PAD]': 29}\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656133427522,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "kClinJNx2gkb",
    "outputId": "b8f254d5-2503-4bcc-c81a-442f32d8ec75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'PER_B', 1: 'DAT_B', 2: '-', 3: 'ORG_B', 4: 'CVL_B', 5: 'NUM_B', 6: 'LOC_B', 7: 'EVT_B', 8: 'TRM_B', 9: 'TRM_I', 10: 'EVT_I', 11: 'PER_I', 12: 'CVL_I', 13: 'NUM_I', 14: 'TIM_B', 15: 'TIM_I', 16: 'ORG_I', 17: 'DAT_I', 18: 'ANM_B', 19: 'MAT_B', 20: 'MAT_I', 21: 'AFW_B', 22: 'FLD_B', 23: 'LOC_I', 24: 'AFW_I', 25: 'PLT_B', 26: 'FLD_I', 27: 'ANM_I', 28: 'PLT_I', 29: '[PAD]'}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqwmtXbBihQM"
   },
   "source": [
    "데이터를 문장들과 개체들로 분리합니다.  \n",
    "tups[0], tups[1],... 에 각각의 문장에 해당하는 단어와 개체 번호가 저장이 되게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1807,
     "status": "ok",
     "timestamp": 1656133430986,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "aBX31tk0HCIP",
    "outputId": "4bc042ed-7644-441c-e6e9-c5c1c0feba53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['비토리오', 'PER_B']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tups = []\n",
    "temp_tup = []\n",
    "temp_tup.append(data[0][1:])\n",
    "sentences = []\n",
    "targets = []\n",
    "for i, j, k in data:\n",
    "  \n",
    "  if i != 1:\n",
    "    temp_tup.append([j,label_dict[k]])\n",
    "  if i == 1:\n",
    "    if len(temp_tup) != 0:\n",
    "      tups.append(temp_tup)\n",
    "      temp_tup = []\n",
    "      temp_tup.append([j,label_dict[k]])\n",
    "\n",
    "tups.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1656133433128,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "weH4ntmzM0If",
    "outputId": "021a30db-f564-45ce-bd04-87cc8439e95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['비토리오', 0], ['양일', 1], ['만에', 2], ['영사관', 3], ['감호', 4], ['용퇴', 2], ['항룡', 2], ['압력설', 2], ['의심만', 2], ['가율', 2]] [['이', 2], ['음경동맥의', 2], ['직경이', 2], ['8', 5], ['19mm입니다', 5], ['.', 2]]\n"
     ]
    }
   ],
   "source": [
    "print(tups[0], tups[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUWClNZni1Pi"
   },
   "source": [
    "tups를 보면 [(단어, 개체), (단어, 개체), (단어, 개체)]의 형식으로 저장이 되어 있는데, 이거를 (단어, 단어, 단어, 단어), (개체, 개체, 개체, 개체) 형식으로 변환하도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "xXcYNq0DTKk7"
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "targets = []\n",
    "for tup in tups:\n",
    "  sentence = []\n",
    "  target = []\n",
    "  sentence.append(\"[CLS]\")\n",
    "  target.append(label_dict['-'])\n",
    "  for i, j in tup:\n",
    "    sentence.append(i)\n",
    "    target.append(j)\n",
    "  sentence.append(\"[SEP]\")\n",
    "  target.append(label_dict['-'])\n",
    "  sentences.append(sentence)\n",
    "  targets.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1656133437381,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "QMmSZyygUatW",
    "outputId": "c9bf8406-5f8f-4cc8-d7ae-e759d8c53117"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '비토리오',\n",
       " '양일',\n",
       " '만에',\n",
       " '영사관',\n",
       " '감호',\n",
       " '용퇴',\n",
       " '항룡',\n",
       " '압력설',\n",
       " '의심만',\n",
       " '가율',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1656133439051,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "qPvbW9H1UeUd",
    "outputId": "fc82d748-c76b-4ef4-e7c1-3bf98b2886be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 0, 1, 2, 3, 4, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7TeCA1I4NkT"
   },
   "source": [
    "## 버트 인풋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2njeCZEKjGdu"
   },
   "source": [
    "구글의 multilinguial-bert를 활용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372,
     "referenced_widgets": [
      "c62d7da2343348dc8148e1a691ad3af3",
      "1e95090edd274934a5e0090ccf9bf805",
      "a343839160da40168a293530f6e891c6",
      "d3b2dd303bff41b48627e0c37d1f1769",
      "fe979e9ba1324ca98a5d66d4cf27106c",
      "f02a367f85384de79e41476fe5e0f087",
      "2254790e3bec4677b25d530b88886fad",
      "a0b1e2617fae43dea9f4a8fc77bc5cc2",
      "ed8fff12181d48dbb378a36bec4a78e8",
      "0655798bf6344fd88f86c51fd264787a",
      "672289ef97c5493eb038f086e71cc7d2",
      "b42dbb2f4ab045a8aa5835c8486ab18c",
      "9d5e6b490c8d4f709b4886071fa2a220",
      "f3e6eaee16f34960a1db20de0551effa",
      "b74b97cff0524555b06a087108298ca1",
      "b6d83f613af847df8ca1dd7bb9611a28",
      "58d5441e7346433dbd0545fcfa590065",
      "ec44b8e5db6c4e448f0b1196c7d3c1a7",
      "85c369bb65eb4bbcaf2048127ca201d8",
      "d4a5f2f957964401b54e721999ee4ed0",
      "119d6204a9c744369a595efa01b18f36",
      "14d828cfb4d34cc0aa51c186b011a099",
      "80e0649c44ba41e788b31043e44ea4e8",
      "d91aa0c1eaba422591fd10638a6cb963",
      "a2d51d6e893c4b3887382bf20d54dc8f",
      "cecd30f1669e4845824ab4f66a4e8bd1",
      "1ec0ea72b4804d33873710d090825366",
      "57222db56f5a40848089ed784d4e2522",
      "58963deabef24bd5b456e4ab4e9e386e",
      "670a9eff23fa4572a397fa86e2883d58",
      "f4c823cb8b694e80908b759ff61de95d",
      "088deb14ba1d46f0ad384663e236cb80",
      "e13fd537d9d84bb69d2635ef5aef0af0"
     ]
    },
    "executionInfo": {
     "elapsed": 1784,
     "status": "ok",
     "timestamp": 1656133501041,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "JfIdFdAVOKfD",
    "outputId": "0d3fd731-e5e8-430d-a324-f73cde71a4c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/vocab.txt from cache at /home/work/.cache/huggingface/transformers/23652104337c09fb424c8d54a5b5921449626b14811e1ce33e9d53cea14eb08f.5c96fdc82531199b4da6fcabb6b273b84bb0f6f10af9211637ccdec0e0ccddda\n",
      "loading file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/special_tokens_map.json from cache at /home/work/.cache/huggingface/transformers/ebf4c4b1a4dc63000d042ab4b372bba6615f28bf7c188aee6463077c971b5eb5.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\n",
      "loading file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/tokenizer_config.json from cache at /home/work/.cache/huggingface/transformers/40b4ffaf0ef8d6f9199c4fffe6bbac53908583f96cbd507fa98832b1d4aa25af.e8305b64b2031f694f527d11857299760b6a9bbe443c14acd5a70c84241009fa\n",
      "loading file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/tokenizer.json from cache at None\n",
      "loading configuration file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/config.json from cache at /home/work/.cache/huggingface/transformers/ab42b6dbba95b60ae9ed47be5d46d0f7c6d5385316d05593be197e0da74c0e1b.a1909b16d8800f08d211389569ece8b08ce65297942a081c16bd2a33dea72f83\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"monologg/koelectra-base-v3-naver-ner\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"PER-B\",\n",
      "    \"2\": \"PER-I\",\n",
      "    \"3\": \"FLD-B\",\n",
      "    \"4\": \"FLD-I\",\n",
      "    \"5\": \"AFW-B\",\n",
      "    \"6\": \"AFW-I\",\n",
      "    \"7\": \"ORG-B\",\n",
      "    \"8\": \"ORG-I\",\n",
      "    \"9\": \"LOC-B\",\n",
      "    \"10\": \"LOC-I\",\n",
      "    \"11\": \"CVL-B\",\n",
      "    \"12\": \"CVL-I\",\n",
      "    \"13\": \"DAT-B\",\n",
      "    \"14\": \"DAT-I\",\n",
      "    \"15\": \"TIM-B\",\n",
      "    \"16\": \"TIM-I\",\n",
      "    \"17\": \"NUM-B\",\n",
      "    \"18\": \"NUM-I\",\n",
      "    \"19\": \"EVT-B\",\n",
      "    \"20\": \"EVT-I\",\n",
      "    \"21\": \"ANM-B\",\n",
      "    \"22\": \"ANM-I\",\n",
      "    \"23\": \"PLT-B\",\n",
      "    \"24\": \"PLT-I\",\n",
      "    \"25\": \"MAT-B\",\n",
      "    \"26\": \"MAT-I\",\n",
      "    \"27\": \"TRM-B\",\n",
      "    \"28\": \"TRM-I\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"AFW-B\": 5,\n",
      "    \"AFW-I\": 6,\n",
      "    \"ANM-B\": 21,\n",
      "    \"ANM-I\": 22,\n",
      "    \"CVL-B\": 11,\n",
      "    \"CVL-I\": 12,\n",
      "    \"DAT-B\": 13,\n",
      "    \"DAT-I\": 14,\n",
      "    \"EVT-B\": 19,\n",
      "    \"EVT-I\": 20,\n",
      "    \"FLD-B\": 3,\n",
      "    \"FLD-I\": 4,\n",
      "    \"LOC-B\": 9,\n",
      "    \"LOC-I\": 10,\n",
      "    \"MAT-B\": 25,\n",
      "    \"MAT-I\": 26,\n",
      "    \"NUM-B\": 17,\n",
      "    \"NUM-I\": 18,\n",
      "    \"O\": 0,\n",
      "    \"ORG-B\": 7,\n",
      "    \"ORG-I\": 8,\n",
      "    \"PER-B\": 1,\n",
      "    \"PER-I\": 2,\n",
      "    \"PLT-B\": 23,\n",
      "    \"PLT-I\": 24,\n",
      "    \"TIM-B\": 15,\n",
      "    \"TIM-I\": 16,\n",
      "    \"TRM-B\": 27,\n",
      "    \"TRM-I\": 28\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35000\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ElectraTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('monologg/koelectra-base-v3-naver-ner')\n",
    "# bert-base-multilingual-cased\n",
    "# monologg/koelectra-base-v3-discriminator\n",
    "# monologg/kobigbird-bert-base\n",
    "# monologg/koelectra-base-v3-naver-ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1656133503248,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "zyapNcSIjnqM",
    "outputId": "38be3013-b56e-47fe-98c7-22b7772b59a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['대한민국', '만세', '.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(\"대한민국 만세.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vpl_V5_HjSxp"
   },
   "source": [
    "여기서부터가 중요한데, 문장을 토크나이징 하고 개체(target)을 토크나이징 한 문장에 맞추도록 하겠습니다.  \n",
    "문장 \"대한민국 만세.\" 는 사실 (대한민국, 개체1), (만세., 개체2) 을 가지고 있는데 토크나이징을 하면 '▁대한민국', '▁만', '세', '.' 로 토크나이징이 됩니다.  \n",
    "여기서 그렇다면 ( ▁대한민국, 개체1) , (▁만, 개체2), (세, 개체2), (., 개체 2) 와 같은 방식으로 각 개체를 부여해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "W3p-p4W0Cc62"
   },
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels):\n",
    "  tokenized_sentence = []\n",
    "  labels = []\n",
    "\n",
    "  for word, label in zip(sentence, text_labels):\n",
    "\n",
    "    tokenized_word = tokenizer.tokenize(word)\n",
    "    n_subwords = len(tokenized_word)\n",
    "\n",
    "    tokenized_sentence.extend(tokenized_word)\n",
    "    labels.extend([label] * n_subwords)\n",
    "\n",
    "  return tokenized_sentence, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0U6gAmqhCvRF"
   },
   "outputs": [],
   "source": [
    "tokenized_texts_and_labels = [tokenize_and_preserve_labels(sent, labs) for sent, labs in zip(sentences, targets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1656133586605,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "Ar9Rd9e-kd3J",
    "outputId": "e91cc98e-e3a2-43c9-c954-8c518c780f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['[CLS]', '비', '##토리', '##오', '양', '##일', '만', '##에', '영사관', '감', '##호', '용', '##퇴', '항', '##룡', '압력', '##설', '의심', '##만', '가', '##율', '[SEP]'], [2, 0, 0, 0, 1, 1, 2, 2, 3, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), (['[CLS]', '이', '음', '##경', '##동', '##맥', '##의', '직경', '##이', '8', '19', '##m', '##m', '##입니다', '.', '[SEP]'], [2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_texts_and_labels[:2])\n",
    "# [(문장, 개체들), (문장, 개체들),...] 형식으로 저장되어 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABHN43Oekyq9"
   },
   "source": [
    "(문장, 개체들), (문장, 개체들) 을 [문장, 문장, 문장, ...] , [개체들, 개체들 개체들,,,,]로 분리해주도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "RNcXW5YeDI_r"
   },
   "outputs": [],
   "source": [
    "tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n",
    "labels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656133617355,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "dUrWCDs00nzw",
    "outputId": "4f0419b0-72c4-4f00-885d-d5eae5cbaf71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '이',\n",
       " '음',\n",
       " '##경',\n",
       " '##동',\n",
       " '##맥',\n",
       " '##의',\n",
       " '직경',\n",
       " '##이',\n",
       " '8',\n",
       " '19',\n",
       " '##m',\n",
       " '##m',\n",
       " '##입니다',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 412,
     "status": "ok",
     "timestamp": 1656133619885,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "SusPxxR40r8E",
    "outputId": "c35990c6-dee1-4494-e956-deef9acd78c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 2, 2]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0W004Btok8Qb"
   },
   "source": [
    "문장의 길이가 상위 2.5%(88) 인 지점을 기준으로 문장의 길이를 정하도록 하겠습니다.  \n",
    "만약 문장의 길이가 88보다 크면 문장이 잘리게 되고, 길이가 88보다 작다면 패딩이 되어 모든 문장의 길이가 88로 정해지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 493,
     "status": "ok",
     "timestamp": 1656133624090,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "QSy59ymvVLiM",
    "outputId": "dc62b490-3faa-424b-e6ec-35812ded0149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.0\n"
     ]
    }
   ],
   "source": [
    "print(np.quantile(np.array([len(x) for x in tokenized_texts]), 0.975))\n",
    "max_len = 83\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3dyW2avlPX4"
   },
   "source": [
    "버트에 인풋으로 들어갈 train 데이터를 만들도록 하겠습니다.  \n",
    "버트 인풋으로는   \n",
    "input_ids : 문장이 토크나이즈 된 것이 숫자로 바뀐 것,   \n",
    "attention_masks : 문장이 토크나이즈 된 것 중에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 마스킹  \n",
    "[input_ids, attention_masks]가 인풋으로 들어갑니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Iy2Aops4DzYa"
   },
   "outputs": [],
   "source": [
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
    "                          maxlen=max_len, dtype=\"int\", value=tokenizer.convert_tokens_to_ids(\"[PAD]\"), truncating=\"post\", padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1656133640683,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "nxn9G_poE-mL",
    "outputId": "54c54857-40d4-437f-ec46-c81ade3cc877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    2,  3240,  3234,  4158,  4089,  4850,  4234, 28875,  4007,\n",
       "          28,  6238,  4036,  4036, 10561,    18,     3,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKfLbZjolxvo"
   },
   "source": [
    "정답에 해당하는 개체들을 만들어 보겠습니다.  \n",
    "패딩에 해당하는 부분은 label_dict([PAD])(29)가 들어가게 되겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "natWaP5FEdDf"
   },
   "outputs": [],
   "source": [
    "tags = pad_sequences([lab for lab in labels], maxlen=max_len, value=label_dict[\"[PAD]\"], padding='post',\\\n",
    "                     dtype='int', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1656133656916,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "BvlojVT_FBw5",
    "outputId": "a8684927-ebdb-44c5-da31-cadc61ecc244"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2,  2,  2,  2,  2,  2,  2,  2,  5,  5,  5,  5,  5,  2,  2, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29,\n",
       "       29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q484H2TAmC9y"
   },
   "source": [
    "어텐션 마스크를 만들어 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "B_AYPsSnFStM"
   },
   "outputs": [],
   "source": [
    "attention_masks = np.array([[int(i != tokenizer.convert_tokens_to_ids(\"[PAD]\")) for i in ii] for ii in input_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1KW7qkTmG5w"
   },
   "source": [
    "train 데이터에서 10% 만큼을 validation 데이터로 분리해 주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "m2Xzq_g9Fcn0"
   },
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,\n",
    "                                                            random_state=20172848, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "gLkM6hwfFjxf"
   },
   "outputs": [],
   "source": [
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
    "                                             random_state=20172848, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MOH3QOJ4ZPc"
   },
   "source": [
    "## 개체명 인식 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13787,
     "status": "ok",
     "timestamp": 1656133741083,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "jrS1jwfoN99Z",
    "outputId": "175e10c0-2a80-46c7-b92a-804da0c03c8b"
   },
   "outputs": [],
   "source": [
    "# TPU 작동을 위해 실행\n",
    "# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
    "# tf.config.experimental_connect_to_cluster(resolver)\n",
    "# tf.tpu.experimental.initialize_tpu_system(resolver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "WLPa5rijMvjq"
   },
   "outputs": [],
   "source": [
    "SEQ_LEN = max_len\n",
    "def create_model():\n",
    "  model = TFBertModel.from_pretrained(\"monologg/koelectra-base-v3-naver-ner\", from_pt=True, num_labels=len(label_dict), output_attentions=False,\n",
    "    output_hidden_states=False)\n",
    "\n",
    "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids') # 토큰 인풋\n",
    "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks') # 마스크 인풋\n",
    "\n",
    "  bert_outputs = model([token_inputs, mask_inputs])\n",
    "  bert_outputs = bert_outputs[0] # shape : (Batch_size, max_len, 30(개체의 총 개수))\n",
    "  nr = tf.keras.layers.Dense(30, activation='softmax')(bert_outputs) # shape : (Batch_size, max_len, 30)\n",
    "  \n",
    "  nr_model = tf.keras.Model([token_inputs, mask_inputs], nr)\n",
    "  \n",
    "  nr_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00002), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "      metrics=['sparse_categorical_accuracy'])\n",
    "  nr_model.summary()\n",
    "  return nr_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PKDPCca4i8N"
   },
   "source": [
    "## 훈련 및 성능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "176308ac93d9466d90f3eff973ae3046",
      "bb3ce1c661524137972ec7475d0147ef",
      "1d3eaa80230744409a3ace58691ef0da",
      "f2f1a251b89f4efab49581e1a833a325",
      "8243a1d788e84aaead38b4a86608c399",
      "be59dd98ae9b4bda842bbc20bad728ee",
      "0b8f2bc25caf474aac013a96f3c672f2",
      "0d53b56372e9429a874167480d007193",
      "c81c0bb10de74d9e8eaf4610efdd560b",
      "18dbad44f79147b8b00cb2c00a6392b0",
      "3c0bda6e8c3d438888ce48315602b3bc",
      "96528105b855488f9c98a05e5e58a4a5",
      "ff2c49620a2349f48a2726380ad7a5d8",
      "f3c012f9e042494b821e88f85cdf104e",
      "e6b2168cb6a34238a9ea50f490b1214f",
      "93d0d4d8781f4517bf7817889d8ef746",
      "efd4a5dfc8cb432a8444d3c4fc12b7e5",
      "47459886d8d646058ac085d901a54733",
      "b6b32c78ee3944498b595f51efc10548",
      "00262006dfe1426da8d2c9fd4a07ead4",
      "21ab86bf8ad04fccb2bdf7a8e9df09af",
      "38aa6cbe94f14c95be20d7c4ad3b9954"
     ]
    },
    "executionInfo": {
     "elapsed": 730840,
     "status": "ok",
     "timestamp": 1656134485166,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "CjKJmS5LNAsd",
    "outputId": "fd333182-07ac-4ae6-cadc-3841571b94b1"
   },
   "outputs": [],
   "source": [
    "# strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
    "# # TPU를 활용하기 위해 context로 묶어주기\n",
    "# with strategy.scope():\n",
    "#   nr_model = create_model()\n",
    "#   nr_model.fit([tr_inputs, tr_masks], tr_tags, validation_data=([val_inputs, val_masks], val_tags), epochs=3, shuffle=False, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "ybu66VKQ4b5H"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/config.json from cache at /home/work/.cache/huggingface/transformers/ab42b6dbba95b60ae9ed47be5d46d0f7c6d5385316d05593be197e0da74c0e1b.a1909b16d8800f08d211389569ece8b08ce65297942a081c16bd2a33dea72f83\n",
      "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.16.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 35000\n",
      "}\n",
      "\n",
      "https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/work/.cache/huggingface/transformers/tmpmter_0b1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eaf4f422fc4d1cbc16b51f105dd1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/pytorch_model.bin in cache at /home/work/.cache/huggingface/transformers/35a755cb971346e43051ed6801bcfe7dce1df8a2c4b6bbf3c00b06270a582a96.9a1ed9e0dfe07093beffc4847b203db18291825f4411dd127918127fb7d2954e\n",
      "creating metadata file for /home/work/.cache/huggingface/transformers/35a755cb971346e43051ed6801bcfe7dce1df8a2c4b6bbf3c00b06270a582a96.9a1ed9e0dfe07093beffc4847b203db18291825f4411dd127918127fb7d2954e\n",
      "loading weights file https://huggingface.co/monologg/koelectra-base-v3-naver-ner/resolve/main/pytorch_model.bin from cache at /home/work/.cache/huggingface/transformers/35a755cb971346e43051ed6801bcfe7dce1df8a2c4b6bbf3c00b06270a582a96.9a1ed9e0dfe07093beffc4847b203db18291825f4411dd127918127fb7d2954e\n",
      "Loading PyTorch weights from /home/work/.cache/huggingface/transformers/35a755cb971346e43051ed6801bcfe7dce1df8a2c4b6bbf3c00b06270a582a96.9a1ed9e0dfe07093beffc4847b203db18291825f4411dd127918127fb7d2954e\n",
      "PyTorch checkpoint contains 112,353,565 parameters\n",
      "Loaded 0 parameters in the TF 2.0 model.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.embeddings.position_ids', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.8.output.LayerNorm.weight', 'classifier.weight', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'classifier.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_word_ids (InputLayer)    [(None, 83)]         0           []                               \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)       [(None, 83)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  112921344   ['input_word_ids[0][0]',         \n",
      "                                thPoolingAndCrossAt               'input_masks[0][0]']            \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 83,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 83, 30)       23070       ['tf_bert_model[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 112,944,414\n",
      "Trainable params: 112,944,414\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1638/1638 [==============================] - 225s 134ms/step - loss: 0.4150 - sparse_categorical_accuracy: 0.8888 - val_loss: 0.3232 - val_sparse_categorical_accuracy: 0.9068\n",
      "Epoch 2/3\n",
      "1638/1638 [==============================] - 218s 133ms/step - loss: 0.2970 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.2455 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 3/3\n",
      "1638/1638 [==============================] - 218s 133ms/step - loss: 0.2240 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f150fe450a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 TPU를 사용하지 않고 GPU를 사용한다면\n",
    "nr_model = create_model()\n",
    "nr_model.fit([tr_inputs, tr_masks], tr_tags, validation_data=([val_inputs, val_masks], val_tags), epochs=3, shuffle=False, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "lmsc9SvzUDYp"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x90MqYVZo6By"
   },
   "outputs": [],
   "source": [
    "y_predicted = nr_model.predict([val_inputs, val_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjRRoCc-XHDV"
   },
   "outputs": [],
   "source": [
    "f_label = [i for i, j in label_dict.items()]\n",
    "val_tags_l = [index_to_ner[x] for x in np.ravel(val_tags).astype(int).tolist()]\n",
    "y_predicted_l = [index_to_ner[x] for x in np.ravel(np.argmax(y_predicted, axis=2)).astype(int).tolist()]\n",
    "f_label.remove(\"[PAD]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GnAt491m2hk"
   },
   "source": [
    "각 개체별 f1 score를 측정하도록 하겠습니다.  \n",
    "참고로 micro avg는 전체 정답을 기준으로 f1 score을 측정한 것이며,  \n",
    "macro avg는 각 개체별 f1 score를 가중평균 한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7005,
     "status": "ok",
     "timestamp": 1656134558389,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "mMRAtG9HZCRS",
    "outputId": "693cb93c-cbc4-4b2e-e9d7-7c09de39cf61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       PER_B       0.89      0.86      0.88     19299\n",
      "       DAT_B       0.93      0.88      0.90      8594\n",
      "           -       0.95      0.97      0.96    239744\n",
      "       ORG_B       0.92      0.86      0.89     21356\n",
      "       CVL_B       0.88      0.80      0.84     26021\n",
      "       NUM_B       0.96      0.94      0.95     22677\n",
      "       LOC_B       0.79      0.83      0.81      8437\n",
      "       EVT_B       0.87      0.79      0.83      5460\n",
      "       TRM_B       0.83      0.79      0.81     10873\n",
      "       TRM_I       0.48      0.55      0.52      1173\n",
      "       EVT_I       0.77      0.87      0.82      2794\n",
      "       PER_I       0.74      0.86      0.79      2689\n",
      "       CVL_I       0.60      0.39      0.47      1324\n",
      "       NUM_I       0.71      0.87      0.78      2654\n",
      "       TIM_B       0.84      0.87      0.86      1005\n",
      "       TIM_I       0.88      0.96      0.92       456\n",
      "       ORG_I       0.73      0.80      0.76      2212\n",
      "       DAT_I       0.84      0.94      0.89      2495\n",
      "       ANM_B       0.70      0.74      0.72      2423\n",
      "       MAT_B       0.51      0.24      0.33        98\n",
      "       MAT_I       0.00      0.00      0.00        14\n",
      "       AFW_B       0.63      0.57      0.60      2181\n",
      "       FLD_B       0.61      0.48      0.54       790\n",
      "       LOC_I       0.13      0.08      0.10        66\n",
      "       AFW_I       0.47      0.54      0.50       712\n",
      "       PLT_B       0.42      0.24      0.30       106\n",
      "       FLD_I       0.00      0.00      0.00        13\n",
      "       ANM_I       0.00      0.00      0.00        29\n",
      "       PLT_I       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.92      0.92      0.92    385695\n",
      "   macro avg       0.62      0.61      0.61    385695\n",
      "weighted avg       0.92      0.92      0.92    385695\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(val_tags_l, y_predicted_l, labels=f_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emi8JP4I4lxX"
   },
   "source": [
    "# 실제 데이터로 실습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "R6Wet-aDstpw"
   },
   "outputs": [],
   "source": [
    "def ner_inference(test_sentence):\n",
    "  \n",
    "\n",
    "  tokenized_sentence = np.array([tokenizer.encode(test_sentence, max_length=max_len, truncation=True, padding='max_length')])\n",
    "  tokenized_mask = np.array([[int(x!=1) for x in tokenized_sentence[0].tolist()]])\n",
    "  ans = nr_model.predict([tokenized_sentence, tokenized_mask])\n",
    "  ans = np.argmax(ans, axis=2)\n",
    "\n",
    "  tokens = tokenizer.convert_ids_to_tokens(tokenized_sentence[0])\n",
    "  new_tokens, new_labels = [], []\n",
    "  for token, label_idx in zip(tokens, ans[0]):\n",
    "    if (token.startswith(\"##\")):\n",
    "      new_labels.append(index_to_ner[label_idx])\n",
    "      new_tokens.append(token[2:])\n",
    "    elif (token=='[CLS]'):\n",
    "      pass\n",
    "    elif (token=='[SEP]'):\n",
    "      pass\n",
    "    elif (token=='[PAD]'):\n",
    "      pass\n",
    "    elif (token != '[CLS]' or token != '[SEP]'):\n",
    "      new_tokens.append(token)\n",
    "      new_labels.append(index_to_ner[label_idx])\n",
    "\n",
    "  for token, label in zip(new_tokens, new_labels):\n",
    "      print(\"{}\\t{}\".format(label, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4988,
     "status": "ok",
     "timestamp": 1656134582666,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "mvYrdoG8t8UV",
    "outputId": "8f864dbe-a078-48ec-976f-209b4fdc1511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_B\t문재인\n",
      "CVL_B\t대통령\n",
      "CVL_B\t은\n",
      "DAT_B\t1953\n",
      "DAT_B\t년\n",
      "DAT_I\t1\n",
      "DAT_I\t월\n",
      "DAT_I\t24\n",
      "DAT_I\t일\n",
      "LOC_B\t경상남도\n",
      "LOC_B\t거제시\n",
      "LOC_B\t에서\n",
      "CVL_B\t아버지\n",
      "PER_B\t문\n",
      "PER_B\t용\n",
      "PER_B\t형\n",
      "PER_B\t과\n",
      "CVL_B\t어머니\n",
      "PER_B\t강한\n",
      "PER_B\t옥\n",
      "-\t사이\n",
      "-\t에서\n",
      "CVL_B\t둘째\n",
      "-\t(\n",
      "CVL_B\t장남\n",
      "-\t)\n",
      "-\t로\n",
      "-\t태어났\n",
      "-\t다\n",
      "-\t.\n"
     ]
    }
   ],
   "source": [
    "ner_inference(\"문재인 대통령은 1953년 1월 24일 경상남도 거제시에서 아버지 문용형과 어머니 강한옥 사이에서 둘째(장남)로 태어났다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1656134595123,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "LP1sNHYuvXKS",
    "outputId": "96ec842b-88eb-431a-ca41-4a002b0b8a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_B\t9\n",
      "NUM_B\t세이\n",
      "NUM_B\t브로\n",
      "-\t구\n",
      "-\t완\n",
      "NUM_B\t30\n",
      "NUM_B\t위\n",
      "NUM_B\t인\n",
      "ORG_B\tLG\n",
      "PER_B\t박찬\n",
      "PER_B\t형\n",
      "PER_B\t은\n",
      "-\t평균\n",
      "-\t자\n",
      "-\t책\n",
      "-\t점\n",
      "-\t이\n",
      "NUM_B\t16\n",
      "NUM_B\t.\n",
      "NUM_B\t45\n",
      "NUM_B\t로\n",
      "-\t준수\n",
      "-\t한\n",
      "-\t편\n",
      "-\t이지\n",
      "-\t만\n",
      "NUM_B\t22\n",
      "NUM_B\t이\n",
      "NUM_B\t닝\n",
      "-\t동안\n",
      "-\t피\n",
      "-\t홈\n",
      "-\t런\n",
      "-\t이\n",
      "NUM_B\t31\n",
      "NUM_B\t개\n",
      "NUM_B\t나\n",
      "-\t된다\n",
      "-\t.\n"
     ]
    }
   ],
   "source": [
    "ner_inference(\"9세이브로 구완 30위인 LG 박찬형은 평균자책점이 16.45로 준수한 편이지만 22이닝 동안 피홈런이 31개나 된다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1191,
     "status": "ok",
     "timestamp": 1656134603015,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "8xAN7BaD1R3O",
    "outputId": "b3d39dd6-40f0-4fb8-b0a4-eebee8ed2b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRM_B\t인공지능\n",
      "TRM_B\t의\n",
      "-\t역사\n",
      "-\t는\n",
      "NUM_B\t20\n",
      "NUM_B\t세기\n",
      "DAT_I\t초반\n",
      "DAT_I\t에서\n",
      "-\t더\n",
      "-\t거슬러\n",
      "-\t올라가\n",
      "-\t보\n",
      "-\t면\n",
      "-\t이미\n",
      "NUM_B\t17\n",
      "NUM_I\t~\n",
      "NUM_I\t18\n",
      "NUM_I\t세기\n",
      "NUM_I\t부터\n",
      "-\t태동\n",
      "-\t하고\n",
      "-\t있\n",
      "-\t었\n",
      "-\t지만\n",
      "-\t이때\n",
      "-\t는\n",
      "TRM_B\t인공지능\n",
      "-\t그\n",
      "-\t자체\n",
      "-\t보\n",
      "-\t다는\n",
      "-\t뇌\n",
      "-\t와\n",
      "-\t마음\n",
      "-\t의\n",
      "-\t관계\n",
      "-\t에\n",
      "-\t관한\n",
      "-\t철학\n",
      "-\t적\n",
      "-\t인\n",
      "-\t논쟁\n",
      "-\t수준\n",
      "-\t에\n",
      "-\t머무르\n",
      "-\t고\n",
      "-\t있\n",
      "-\t었\n",
      "-\t다\n",
      "-\t.\n",
      "-\t그럴\n",
      "-\t수\n",
      "-\t밖에\n",
      "-\t없\n",
      "-\t는\n",
      "-\t것\n",
      "-\t이\n",
      "-\t당시\n",
      "-\t에\n",
      "-\t는\n",
      "-\t인간\n",
      "-\t의\n",
      "-\t뇌\n",
      "-\t말\n",
      "-\t고\n",
      "-\t는\n",
      "-\t정보\n",
      "-\t처리\n",
      "-\t기계\n",
      "-\t가\n",
      "-\t존재\n",
      "-\t하\n",
      "-\t지\n",
      "-\t않\n",
      "-\t았\n",
      "-\t기\n",
      "-\t때문\n",
      "-\t이다\n",
      "-\t.\n"
     ]
    }
   ],
   "source": [
    "ner_inference(\"인공지능의 역사는 20세기 초반에서 더 거슬러 올라가보면 이미 17~18세기부터 태동하고 있었지만 이때는 인공지능 그 자체보다는 뇌와 마음의 관계에 관한 철학적인 논쟁 수준에 머무르고 있었다. 그럴 수 밖에 없는 것이 당시에는 인간의 뇌 말고는 정보처리기계가 존재하지 않았기 때문이다. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1656134673112,
     "user": {
      "displayName": "이지평",
      "userId": "04288060060884002898"
     },
     "user_tz": -540
    },
    "id": "cIt7_nTdUIqJ",
    "outputId": "249e282b-87ad-4a7c-8be1-587c1303c579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\t안녕\n",
      "-\t하\n",
      "-\t세요\n",
      "-\t.\n",
      "-\t저\n",
      "-\t는\n",
      "PER_B\t이지\n",
      "PER_B\t평\n",
      "PER_B\t이\n",
      "PER_B\t라고\n",
      "-\t합니다\n",
      "-\t.\n",
      "ORG_B\t국민대\n",
      "ORG_B\t학교\n",
      "ORG_B\t에\n",
      "-\t다니\n",
      "-\t고\n",
      "-\t있\n",
      "-\t으며\n",
      "-\t,\n",
      "-\t현재\n",
      "-\t는\n",
      "NUM_B\t4\n",
      "NUM_B\t학\n",
      "NUM_B\t년\n",
      "NUM_B\t1\n",
      "NUM_B\t학\n",
      "NUM_B\t기\n",
      "NUM_B\t를\n",
      "-\t마치\n",
      "-\t고\n",
      "EVT_B\tSKT\n",
      "EVT_B\tAI\n",
      "EVT_I\tFe\n",
      "EVT_I\tll\n",
      "EVT_I\tow\n",
      "EVT_I\tship\n",
      "DAT_B\t4\n",
      "DAT_B\t기에\n",
      "-\t참여\n",
      "-\t중\n",
      "-\t입니다\n",
      "-\t.\n"
     ]
    }
   ],
   "source": [
    "ner_inference(\"안녕하세요. 저는 이지평이라고 합니다. 국민대학교에 다니고 있으며, 현재는 4학년 1학기를 마치고 SKT AI Fellowship 4기에 참여 중입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "egwhO6bVUV9h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER_B\t짱\n",
      "PER_B\t구\n",
      "PER_B\t는\n",
      "-\t못\n",
      "-\t말\n",
      "-\t려\n"
     ]
    }
   ],
   "source": [
    "ner_inference(\"짱구는 못말려\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "5_(BERT_실습)한국어 개체명 인식.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/kimwoonggon/publicservant_AI/blob/master/5_(BERT_%EC%8B%A4%EC%8A%B5)%ED%95%9C%EA%B5%AD%EC%96%B4_%EA%B0%9C%EC%B2%B4%EB%AA%85_%EC%9D%B8%EC%8B%9D.ipynb",
     "timestamp": 1656133170934
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "TensorFlow 2.8 on Python 3.8 (CUDA 11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00262006dfe1426da8d2c9fd4a07ead4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0655798bf6344fd88f86c51fd264787a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "088deb14ba1d46f0ad384663e236cb80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b8f2bc25caf474aac013a96f3c672f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0d53b56372e9429a874167480d007193": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119d6204a9c744369a595efa01b18f36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14d828cfb4d34cc0aa51c186b011a099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "176308ac93d9466d90f3eff973ae3046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb3ce1c661524137972ec7475d0147ef",
       "IPY_MODEL_1d3eaa80230744409a3ace58691ef0da",
       "IPY_MODEL_f2f1a251b89f4efab49581e1a833a325"
      ],
      "layout": "IPY_MODEL_8243a1d788e84aaead38b4a86608c399"
     }
    },
    "18dbad44f79147b8b00cb2c00a6392b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d3eaa80230744409a3ace58691ef0da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d53b56372e9429a874167480d007193",
      "max": 625,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c81c0bb10de74d9e8eaf4610efdd560b",
      "value": 625
     }
    },
    "1e95090edd274934a5e0090ccf9bf805": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f02a367f85384de79e41476fe5e0f087",
      "placeholder": "​",
      "style": "IPY_MODEL_2254790e3bec4677b25d530b88886fad",
      "value": "Downloading: 100%"
     }
    },
    "1ec0ea72b4804d33873710d090825366": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21ab86bf8ad04fccb2bdf7a8e9df09af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2254790e3bec4677b25d530b88886fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38aa6cbe94f14c95be20d7c4ad3b9954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3c0bda6e8c3d438888ce48315602b3bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47459886d8d646058ac085d901a54733": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "57222db56f5a40848089ed784d4e2522": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58963deabef24bd5b456e4ab4e9e386e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58d5441e7346433dbd0545fcfa590065": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "670a9eff23fa4572a397fa86e2883d58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "672289ef97c5493eb038f086e71cc7d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80e0649c44ba41e788b31043e44ea4e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d91aa0c1eaba422591fd10638a6cb963",
       "IPY_MODEL_a2d51d6e893c4b3887382bf20d54dc8f",
       "IPY_MODEL_cecd30f1669e4845824ab4f66a4e8bd1"
      ],
      "layout": "IPY_MODEL_1ec0ea72b4804d33873710d090825366"
     }
    },
    "8243a1d788e84aaead38b4a86608c399": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85c369bb65eb4bbcaf2048127ca201d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93d0d4d8781f4517bf7817889d8ef746": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96528105b855488f9c98a05e5e58a4a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff2c49620a2349f48a2726380ad7a5d8",
       "IPY_MODEL_f3c012f9e042494b821e88f85cdf104e",
       "IPY_MODEL_e6b2168cb6a34238a9ea50f490b1214f"
      ],
      "layout": "IPY_MODEL_93d0d4d8781f4517bf7817889d8ef746"
     }
    },
    "9d5e6b490c8d4f709b4886071fa2a220": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58d5441e7346433dbd0545fcfa590065",
      "placeholder": "​",
      "style": "IPY_MODEL_ec44b8e5db6c4e448f0b1196c7d3c1a7",
      "value": "Downloading: 100%"
     }
    },
    "a0b1e2617fae43dea9f4a8fc77bc5cc2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2d51d6e893c4b3887382bf20d54dc8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_670a9eff23fa4572a397fa86e2883d58",
      "max": 375,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4c823cb8b694e80908b759ff61de95d",
      "value": 375
     }
    },
    "a343839160da40168a293530f6e891c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0b1e2617fae43dea9f4a8fc77bc5cc2",
      "max": 248477,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed8fff12181d48dbb378a36bec4a78e8",
      "value": 248477
     }
    },
    "b42dbb2f4ab045a8aa5835c8486ab18c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d5e6b490c8d4f709b4886071fa2a220",
       "IPY_MODEL_f3e6eaee16f34960a1db20de0551effa",
       "IPY_MODEL_b74b97cff0524555b06a087108298ca1"
      ],
      "layout": "IPY_MODEL_b6d83f613af847df8ca1dd7bb9611a28"
     }
    },
    "b6b32c78ee3944498b595f51efc10548": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6d83f613af847df8ca1dd7bb9611a28": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b74b97cff0524555b06a087108298ca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_119d6204a9c744369a595efa01b18f36",
      "placeholder": "​",
      "style": "IPY_MODEL_14d828cfb4d34cc0aa51c186b011a099",
      "value": " 173/173 [00:00&lt;00:00, 2.93kB/s]"
     }
    },
    "bb3ce1c661524137972ec7475d0147ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be59dd98ae9b4bda842bbc20bad728ee",
      "placeholder": "​",
      "style": "IPY_MODEL_0b8f2bc25caf474aac013a96f3c672f2",
      "value": "Downloading: 100%"
     }
    },
    "be59dd98ae9b4bda842bbc20bad728ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c62d7da2343348dc8148e1a691ad3af3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1e95090edd274934a5e0090ccf9bf805",
       "IPY_MODEL_a343839160da40168a293530f6e891c6",
       "IPY_MODEL_d3b2dd303bff41b48627e0c37d1f1769"
      ],
      "layout": "IPY_MODEL_fe979e9ba1324ca98a5d66d4cf27106c"
     }
    },
    "c81c0bb10de74d9e8eaf4610efdd560b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cecd30f1669e4845824ab4f66a4e8bd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_088deb14ba1d46f0ad384663e236cb80",
      "placeholder": "​",
      "style": "IPY_MODEL_e13fd537d9d84bb69d2635ef5aef0af0",
      "value": " 375/375 [00:00&lt;00:00, 9.54kB/s]"
     }
    },
    "d3b2dd303bff41b48627e0c37d1f1769": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0655798bf6344fd88f86c51fd264787a",
      "placeholder": "​",
      "style": "IPY_MODEL_672289ef97c5493eb038f086e71cc7d2",
      "value": " 243k/243k [00:00&lt;00:00, 1.03MB/s]"
     }
    },
    "d4a5f2f957964401b54e721999ee4ed0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d91aa0c1eaba422591fd10638a6cb963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57222db56f5a40848089ed784d4e2522",
      "placeholder": "​",
      "style": "IPY_MODEL_58963deabef24bd5b456e4ab4e9e386e",
      "value": "Downloading: 100%"
     }
    },
    "e13fd537d9d84bb69d2635ef5aef0af0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6b2168cb6a34238a9ea50f490b1214f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_21ab86bf8ad04fccb2bdf7a8e9df09af",
      "placeholder": "​",
      "style": "IPY_MODEL_38aa6cbe94f14c95be20d7c4ad3b9954",
      "value": " 681M/681M [00:14&lt;00:00, 46.3MB/s]"
     }
    },
    "ec44b8e5db6c4e448f0b1196c7d3c1a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed8fff12181d48dbb378a36bec4a78e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "efd4a5dfc8cb432a8444d3c4fc12b7e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f02a367f85384de79e41476fe5e0f087": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2f1a251b89f4efab49581e1a833a325": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18dbad44f79147b8b00cb2c00a6392b0",
      "placeholder": "​",
      "style": "IPY_MODEL_3c0bda6e8c3d438888ce48315602b3bc",
      "value": " 625/625 [00:00&lt;00:00, 9.85kB/s]"
     }
    },
    "f3c012f9e042494b821e88f85cdf104e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6b32c78ee3944498b595f51efc10548",
      "max": 714314041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00262006dfe1426da8d2c9fd4a07ead4",
      "value": 714314041
     }
    },
    "f3e6eaee16f34960a1db20de0551effa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85c369bb65eb4bbcaf2048127ca201d8",
      "max": 173,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4a5f2f957964401b54e721999ee4ed0",
      "value": 173
     }
    },
    "f4c823cb8b694e80908b759ff61de95d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe979e9ba1324ca98a5d66d4cf27106c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff2c49620a2349f48a2726380ad7a5d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efd4a5dfc8cb432a8444d3c4fc12b7e5",
      "placeholder": "​",
      "style": "IPY_MODEL_47459886d8d646058ac085d901a54733",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
